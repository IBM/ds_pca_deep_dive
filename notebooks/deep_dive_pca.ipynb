{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dive into Principal Component Analysis (PCA).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Table of Contents\n",
    "\n",
    "1. [Introduction.](#introduction)\n",
    "\n",
    "2. [Principal Component Analysis (PCA) Intuition.](#intuition)\n",
    "\n",
    "3. [PCA Mathemathical Formulation.](#math)\n",
    "\n",
    "4. [Principal Component Analysis (PCA) in Practice.](#practice)\n",
    "\n",
    "  4.1 [PCA for Dimension Reduction.](#dim_reduction)\n",
    "  \n",
    "  4.2 [PCA for Visualization and Better Insights.](#visualization)\n",
    "  \n",
    "  4.3 [PCA for Noise Filtering.](#filter_noise)\n",
    "  \n",
    "  4.4 [PCA as a Preprocessor for ML algorithms.](#pre_processor)\n",
    "  \n",
    "5. [Summary.](#summary)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Introduction<a name=\"introduction\"></a>\n",
    "\n",
    "In this Notebook, we will explore Principal Component Analysis from various perspectives.\n",
    "\n",
    "We will first give a short intuitive explanation for principal component analysis and why it makes sense. Then we will go deeper into the actual derivation of Principal Components using the principle of maximizing the total projected variances onto components. Once we have understood the theory and concept, we will dive deeper into the use cases and examples. We will consider four scenarios with examples.\n",
    "\n",
    "  1. Dimension Reduction\n",
    "  2. Visualization\n",
    "  3. Noise Filtering\n",
    "  4. As a pre-processor for ML algorithms.\n",
    "\n",
    "In the end, we will summarize our discussion with various pointers to alternatives to PCA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Principal Component Analysis Intuition.<a name=\"intuition\"></a>\n",
    "\n",
    "##### 2.1. Why Dimensionality reduction make sense?\n",
    "\n",
    "In real life, the data is generated from a fixed degree of freedom and when we collect data, there is noise added or sometimes we don't know the actual dimensions . These all mean that to represent a data, we use a lot of dimension then that was used by data generation process. However, since we don't always have information about the data generation, it would be nice to have a tool, which can remove the unnecessary dimensions. \n",
    "\n",
    "Examples: Consider the black and white image of digits like in [MNIST Digit Database](https://en.wikipedia.org/wiki/MNIST_database). Each image is 28x28 == 784 pixels or 784 dimensions. However, most of the pixels are white and most of the digits are generated by a combination of vertical, horizontal and rotation stroke i.e data is generated by about 3 dimensions.\n",
    "\n",
    "##### 2.2. What is Dimensionality Reduction\n",
    "\n",
    "Dimensionality reduction is choosing a basis or mathematical representation within which you can describe most but not all of the variance within your data, thereby retaining the relevant information, while reducing the amount of information necessary to represent it. There are a variety of techniques for doing this including but not limited to PCA, [ICA](https://en.wikipedia.org/wiki/Independent_component_analysis), and [Matrix Feature Factorization](https://en.wikipedia.org/wiki/Matrix_decomposition). These will take existing data and reduce it to the most discriminative components. All of these allow you to represent most of the information in your dataset with fewer, more discriminative features.\n",
    "\n",
    "##### 2.3. Why is Dimensionality Reduction Useful?\n",
    "\n",
    "In terms of performance, having data of high dimensions is problematic because:\n",
    "\n",
    "* It can mean high computational cost to perform learning and inference and\n",
    "\n",
    "* It often leads to over-fitting when learning a model, which means that the model will perform well on the training data but poorly on test data.\n",
    "\n",
    "Dimensionality reduction addresses both of these problems, while (hopefully) preserving most of the relevant information in the data needed to learn accurate, predictive models.\n",
    "\n",
    "Also note that, in general visualization of lower dimension data and its interpretation are more straightforward and it could be used for getting better insights into the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Intuition of PCA.\n",
    "\n",
    "The intuition behind PCA is remarkably simple. What we ask is given a dataset, can we represent the dataset using fewer number of dimensions?\n",
    "\n",
    "In the following picture, we can see that the original data spans in 3D but most of the information is contained in the 2D plain which is oriented around at 45 degree on x-y plane.\n",
    "The second picture shows how the 3D information is represented in the 2D plain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\" alt=\"Drawing\" style=\"width:1000px;\"/>\n",
    "\n",
    "\n",
    "[Source [Matthias Scholz Thesis](http://phdthesis-bioinformatics-maxplanckinstitute-molecularplantphys.matthias-scholz.de/)] [License a Creative Commons - Attribution license]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 PCA transformation\n",
    "\n",
    "In general, dataset will be spread across multiple axes in the n-dimensional space. It is natural that the spread (aka variance) will be different in the direction of those axes. The next question, we  ask is : Can we only pick the axes where the variances are high and remove the axes and data variances are low. Note that the maximum variance need not be in the direction of the original axes but in the direction which is the linear combination of the subset of the original axes. Principal component analysis (PCA) rotates the original data space such that the axes of the new coordinate system points to the direction of the highest variance of the data. User can choose a subset of the rotated axes thus resulting in the reduction of noise and also reduction in the data size.\n",
    "\n",
    "See the following links for more details:\n",
    "\n",
    "[nlpca](http://www.nlpca.org/pca_principal_component_analysis.html)\n",
    "\n",
    "[wiki](https://en.wikipedia.org/wiki/Principal_component_analysis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA Mathemathical formulation.<a name=\"math\"></a>\n",
    "\n",
    "If we would like to approximate the real dataset with an approximate dataset, we would need to have some way to measure the discrepancy between real and approximate dataset. There are multiple ways to derive PCA, we will choose one of them i.e variance of the projected data onto the reduced rotated dimensional axes i.e principal component is maximized. Since having a maximum variances preserve as must information as possible as compare to minimum variances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move forward, let's define some of the terms:\n",
    "##### 3.1 Convention Used.\n",
    "\n",
    "\n",
    "| Symbol        | description                                                 |\n",
    "|:--------------|:------------------------------------------------------------|\n",
    "| $x_{i}$       | scalar is represented as lowercase with dimensional subscript $i$ |\n",
    "| $\\mathbf{x} $ | vector is represented as a bold lowercase                   |\n",
    "| $\\mathbf{X} $ | matrix is represented as bold uppercase                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. Definition of Statistical and Matrix Operations.\n",
    "\n",
    "Lets defined some of terms related to Statistics and Matrix operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1. Scalar Variable.\n",
    "\n",
    "When we collect data each of the measurement is scalar. We could collect N samples of each scalar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3.2.2. Vector variable.\n",
    "\n",
    "During data collection, we might measure various attributes, for example age, gender etc of the test subject.\n",
    "To compactly represent M scalars for each subject i.e sample, vector is used, it is just a tuple of M scalars and uniquely describes a point in M dimensional space.\n",
    "\n",
    "###### Represenation of a Sample using Vector.\n",
    "Let the original input dataset be represented by M number of dimensions i.e each sample consist of M different 1D data point and together they form a sample data point column vector. $ \\mathbf{x}  = (x_{1}, x_{2} \\cdots x_{M})^{T} $. \n",
    "\n",
    "\n",
    "Since we will be having N different data point, we would like to sub-script $ i $ for the i'th sample and the i'th data point vector is \n",
    "$$ \\mathbf{x_{i}}  = (x_{i1}, x_{i2} \\cdots , x_{iM})^{T} $$ \n",
    "\n",
    "(**Note**: We use Transpose operation to compactly represent column vector as row vector.)\n",
    "\n",
    "##### Representation of a Principal Component using Vector.\n",
    "\n",
    "As we talked before that we will first project the standardized dataset on to K principal \n",
    "components with $ K \\in \\{{1, 2, \\cdots, M}\\}$. Lets call $\\mathbf{p_{j}}$ a M dimentional vector representing the direction of j'th principal \n",
    "$$ \\mathbf{p_{j}}  = (p_{j1}, p_{k2} \\cdots , p_{jM})^{T} $$ \n",
    "\n",
    "\n",
    "There are a couple of points to be noted about $\\mathbf{p_{j}}$\n",
    "\n",
    "* each $\\mathbf{p_{j}}$ lives in the space of M dimension i.e space of standardized or original data space i.e $dim(\\mathbf{p_{j}}) == M$\n",
    "\n",
    "* Since we are only interested in the direction we will assume i.e each of $p_{j}$ is [unit vector](https://en.wikipedia.org/wiki/Unit_vector) i.e $\\|\\mathbf{p_{j}}\\|_{2}==1$ without loss of generality.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3.2.3. Matrix Variable.\n",
    "\n",
    "##### Representation of Whole Dataset.\n",
    "As we noted in previous sub section that each subject or sample can be represented by one column vector. If we take N such measurement, we can compactly represent all those N measurements across M dimension using $ N \\times M $ matrix.\n",
    "\n",
    "$$ \\mathbf{X} = ( \\mathbf{x_{1}}^{T}, \\mathbf{x_{2}}^{T}, \\cdots  \\mathbf{x_{i}}^{T} \\cdots ,\\mathbf{x_{n}}^{T} )^{T}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "###### Representation of K Principal Component Direction.\n",
    "\n",
    "There are total K numbers of principal components i.e we have $\\mathbf{p_{1}}, \\mathbf{p_{2}}, \\cdots , \\mathbf{p_{k}}$ i.e we can compactly represent them as a $K X M $ matrix. $\\mathbf{P} = ( \\mathbf{p_{1}}^{T}, \\mathbf{p_{2}}^{T}, \\cdots  \\mathbf{p_{i}}^{T} \\cdots ,\\mathbf{p_{k}}^{T} )^{T}$ with $ K \\in \\{{1, 2, \\cdots, M}\\}$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.4. Standardization of Data Points.\n",
    "\n",
    "\n",
    "To get standardized data, we will shift each of the dimensions by its mean. The advantage of this would be simpler math.\n",
    "\n",
    "We would also like to divide it by dispersion i.e standard deviation because this will remove any bias associated with measuring units i.e measurement in inch vs cm etc.\n",
    "\n",
    "it means new i'th sample is represented as $\\mathbf{s_{i}}  = (s_{i1}, s_{i2} \\cdots , s_{iM})^{T}$ i.e a column vector of standardized dimensions $s_{ij}$\n",
    "\n",
    "Each of the i'th samples' j'th dimension is represented as follows\n",
    "\n",
    "$$s_{ij} = \\frac{x_{ij} - \\overline{x_{j}}}{ \\sigma_{x_{j}}}$$\n",
    "\n",
    "\n",
    " \n",
    "Where\n",
    "  * Average for j'th dimension $  \\Rightarrow  \\overline{x_{j}} = \\frac{1}{N}\\Sigma x_{ij} $\n",
    "  \n",
    "  * Standard Deviation for j'th dimension  $  \\Rightarrow  \\sigma_{x_{j}} = \\sqrt[2]{\\frac{1}{N-1}\\sum_{i=1}^{N-1}(x_{ij} - \\overline{x_{j}})^2}$\n",
    "  \n",
    "  \n",
    "and new standardized data matrix of size $ N \\times M $ becomes \n",
    "\n",
    "$ \\mathbf{S} = ( \\mathbf{s_{1}}^{T}, \\mathbf{s_{2}}^{T}, \\cdots  \\mathbf{s_{i}}^{T} \\cdots ,\\mathbf{s_{n}}^{T} )^{T}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3.2.5. Variance of Scalar Variable.\n",
    "\n",
    "\n",
    "  If we take N samples of a random variable $v$ with zero mean, then its [variance](https://en.wikipedia.org/wiki/Variance) is given by \n",
    "$$variance(v) = \\frac{1}{N}\\sum_{i=1}^{N}v^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 3.2.6. Length of a Vector.\n",
    "\n",
    "M dimensional Vector is a point in M dimensional space and it has direction as well as magnitude. The idea of vector norm is motivated from the euclidean distance in our usual 3D space. If we have a point in 3D specified by vector $\\mathbf{v} = (x, y, z)$ then its distance from origin or length is given by following expression\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "dist(\\mathbf{v}, \\mathbf{0}) &= norm_{2}(\\mathbf{v}) \\\\\n",
    "& = \\|\\mathbf{v}\\|_{2} \\\\\n",
    "& = \\sqrt[2]{x^{2} + y^{2} + z^{2}} \\\\\n",
    "& = \\sqrt[2]{\\mathbf{v}^{T}\\mathbf{v}} && \\text{from defn of dot_product)}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "To generalize, above expression, if we have M dimensional vector $\\mathbf{p_{k}}$ then its $norm_2$ is given as:\n",
    "\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "dist(\\mathbf{p_{k}}, \\mathbf{0}) &= norm_{2}(\\mathbf{p_{k}}) \\\\\n",
    "& = \\|\\mathbf{p_{k}}\\|_{2} \\\\\n",
    "& = \\sqrt[2]{ p_{k1}^{2} + p_{k2}^{2} + \\cdots + p_{kj}^{2} + \\cdots + p_{kM}^{2}} && \\text{; $ p_{kj}\\ \\forall j \\in \\{{1, 2, \\cdots, M}\\} $ are the dimensions of vector $\\mathbf{p_k}$}\\\\\n",
    "& = \\sqrt[2]{\\mathbf{p_{k}}^{T}\\mathbf{p_{k}}} && \\text{;from defn of dot_product}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3.2.7. Vector Projection.\n",
    " [Vector projection](https://en.wikipedia.org/wiki/Vector_projection) is given by [dot product](https://en.wikipedia.org/wiki/Dot_product). i.e if we project vector $\\mathbf{a}$ onto vector $\\mathbf{b}$, then followings holds true:\n",
    "\n",
    "$$ project\\_\\mathbf{a}\\_onto\\_\\mathbf{b} = dot\\_product(\\mathbf{a}, \\mathbf{b}) = \\mathbf{a} \\cdot \\mathbf{b} = \\mathbf{a}^{T} \\mathbf{b} $$\n",
    "\n",
    "\n",
    "\n",
    " In our case, projection  on a M dimensional point $\\mathbf{s_{i}}$ vector onto a principal component $\\mathbf{p_{k}}$ is given by dot product as follows:\n",
    "\n",
    "$$ project\\_\\mathbf{s_{i}}\\_onto\\_\\mathbf{p_{k}} = dot\\_product(\\mathbf{s_{i}}, \\mathbf{p_{k}}) = \\mathbf{s_{i}} \\cdot \\mathbf{p_{k}} =  \\mathbf{s_{i}}^{T} \\mathbf{p_{k}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.8. How to Represent a Scalar using Dot Product.\n",
    "\n",
    "While deriving PCA, we will use this standard trick of representing a scalar as a dot product.\n",
    "If a variable $v$ is scalar, then its square can be represented as dot product as follows:\n",
    "  \n",
    "$$ v^{2} = dot\\_prodct(v, v) = v \\cdot v = v^{T}v$$\n",
    "\n",
    "i.e self dot product of scalar variable is just its multiplication with itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.9. Transpose of Product of Matrices.\n",
    "\n",
    " [Transpose of the product of Matrices $\\mathbf{a}$ and $\\mathbf{b}$](https://proofwiki.org/wiki/Transpose_of_Matrix_Product) is given by following:\n",
    " \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "(\\mathbf{a}\\mathbf{b})^{T} = \\mathbf{b}^{T}\\mathbf{a}^{T} && \\text{  ; where $\\mathbf{a}$ is $K X M$ and $\\mathbf{b}$ is $M X K$ }\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.10 Covariance of M Dimensional Vector.\n",
    "\n",
    "If we collect N samples for one dimensional data, then we know that using mean and variance (aka sufficient statistics), we can get a good perspective on data. In short, using sufficient statistics i.e mean and variance allows us to have compression and remove the noise. The natural question is what to do when we have more than one dimensions to data i.e say M dimensions. Well how about characterizing it by M mean and M variances? This seems intuitively right, but here we are assuming that there is no co-relation or co-variance between any two dimensions. What if we want to account for this? The approach would be to compute variances between two dimensions and it is called co-variance. Since we have assumed without loss of generality that each dimension has zero mean. We can define covariance between them. Thus, with about $MxM$ parameters, we can represent our dataset.\n",
    "\n",
    "We will assume the dataset as described in section 3.2.4 above. Where we collect N samples for each of M dimensions.\n",
    "\n",
    "Let's also define $\\mathbf{ss_{k}}$ as the k'th column of matrix $\\mathbf{S}$ i.e $\\mathbf{ss_{k}}$ represents all the samples we collected for the k'th dimensions and is defined as\n",
    "$$ \\mathbf{ss_{k}} = (s_{1k}, s_{2k}, \\cdots ,s_{nk})^{T} $$\n",
    "\n",
    "The [Co-variance Matrix](https://en.wikipedia.org/wiki/Covariance_matrix) is $M \\times M$ matrix and is defined as:\n",
    "\n",
    "$$\\Sigma = (\\Sigma_{ij}) \\in \\Re^{M \\times M}$$\n",
    "\n",
    "* Each $\\Sigma_{ij}$ is a covariance of i'th and j'th dimensions and is given by\n",
    "\n",
    "$$ \n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\Sigma_{ij} &= cov(\\mathbf{ss_{i}}, \\mathbf{ss_{j}}) \\\\\n",
    " &= \\mathbb{E}(\\mathbf{ss_{i}}, \\mathbf{ss_{j}}) && \\text{ ;from the definition of co-variance with zero means}\\\\\n",
    " &= \\frac{1}{N} \\sum_{m=1}^{N}(ss_{mi} \\times {ss_{mj}})  && \\text{ ;from the definition expectation}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Note that the above expression can be compactly represented in [co-variance matrix form](https://en.wikipedia.org/wiki/Covariance_matrix#Definition)\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\Sigma &= \\mathbb{E}(\\mathbf{s}\\mathbf{s}^{T}) && \\text{ ;from definition of co-variance}\\\\\n",
    "& = \\frac{1}{N}\\sum_{i=1}^{N}(\\mathbf{s_{i}}\\mathbf{s_{i}}^{T}) && \\text{ ;from the definition expectation} \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Derivation using Total Maximum Variances of Data Projection.\n",
    "\n",
    "Now we are ready to derive the expression for all the principal components. Note that since, we would like to maximize the total projected variances. Total variances will be sum of the variances along each of the principal component. So to simplify our problem statement, we can find the expression for an arbitrary principal component i.e $\\mathbf{p_{k}}$ and then generalize it for other principal components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "##### 3.3.1 Finding best Principal Component by Maximizing Projected Variances onto Principal Component.\n",
    "\n",
    "We can write variance of the projection of M dimensional N points (i.e vectors) $\\mathbf{s_{1}}, \\mathbf{s_{1}}, \\cdots , \\mathbf{s_{n}}$ onto a arbitrary principal component $\\mathbf{p_{k}} ,\\ \\ \\ \\forall k \\in {\\{1, 2, \\cdots, M}\\}$  as \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  total\\_projected\\_variance\\_on\\_\\mathbf{p_{k}} & = variance\\_of\\_projection\\_of\\_N\\_points\\_onto\\_\\mathbf{p_{k}} \\\\\n",
    "  & = variance(projection(\\mathbf{s_{1}}, \\mathbf{p_{k}}), projection(\\mathbf{s_{2}}, \\mathbf{p_{k}}) \\cdots, projection(\\mathbf{s_{n}}, \\mathbf{p_{k}}) ) \\\\\n",
    "  & = variance(\\mathbf{s_{1}}^{T}\\mathbf{p_{k}}, \\mathbf{s_{2}}^{T}\\mathbf{p_{k}} \\cdots,\\mathbf{s_{n}}^{T}\\mathbf{p_{k}} )) && \\text{;see projection at 3.2.7} \\\\\n",
    "  & = \\frac{1}{N}\\sum_{i=1}^{N}(\\mathbf{s_{i}}^{T} \\mathbf{p_{k}})^2 & & \\text{;see variance at 3.2.5} \\\\\n",
    "  & = \\frac{1}{N} \\sum_{i=1}^{N}(\\mathbf{s_{i}}^{T} \\mathbf{p_{k}})^{T}(\\mathbf{s_{i}}^{T} \\mathbf{p_{k}}) && \\text{;Scalar and dot product representation (see 3.2.8 above)} \\\\\n",
    "  & = \\frac{1}{N} \\sum_{i=1}^{N}(\\mathbf{p_{k}}^{T}(\\mathbf{s_{i}}^{T})^{T})(\\mathbf{s_{i}}^{T} \\mathbf{p_{k}}) && \\text{;Transpose of matrix product (see 3.2.9 above)} \\\\\n",
    "    & = \\frac{1}{N} \\sum_{i=1}^{N}(\\mathbf{p_{k}}^{T}\\mathbf{s_{i}})(\\mathbf{s_{i}}^{T} \\mathbf{p_{k}}) && \\text{;Since transpose is an involution i.e self inverse i.e transpose of transpose is original vector} \\\\\n",
    "  & = \\frac{1}{N} \\sum_{i=1}^{N}\\mathbf{p_{k}}^{T}(\\mathbf{s_{i}}\\mathbf{s_{i}}^{T}) \\mathbf{p_{k}} && \\text{;Associativity of matrix product} \\\\\n",
    "  & = \\mathbf{p_{k}}^{T}(\\frac{1}{N} \\sum_{i=1}^{N}(\\mathbf{s_{i}}\\mathbf{s_{i}}^{T})) \\mathbf{p_{k}} && \\text{;Since summation doesn't involve k, we can bring terms containing k out of summation} \\\\\n",
    " & = \\mathbf{p_{k}}^{T} \\mathbf{\\Sigma} \\mathbf{p_{k}} && \\text{;From the defn of covariance matrix as explained in 3.2.10}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As explained in previous sections, we would like to maximize the projected variances onto an arbitrary principal component. Above expression of total projected variances on an arbitrary principal component $\\mathbf{p_{k}}$ can be cast as the constrained maximization problem aka as [Method of Lagrange Multipliers](https://en.wikipedia.org/wiki/Lagrange_multiplier). \n",
    "\n",
    "What should be the constraints? The obvious constraint on vector $\\mathbf{p_{k}}$ is that it has to be of constant length. \n",
    "\n",
    "Why is it so? To understand it, lets assume that it is not constant and is variable. Since the expression of maximum projected variances involves product of  $\\mathbf{p_{k}}$ and $\\Sigma$,  the maximizing process will make length of $\\mathbf{p_{k}}$ i.e $norm_2(\\mathbf{p_{k}})$ (see 3.2.2  above), to be as maximum as possible which is infinity. And when $norm_2(\\mathbf{p_{k}}) \\rightarrow \\infty $, we don't have a solution and hence it proves that $norm_2(\\mathbf{p_{k}})$ must be constant to have a reasonable solution.\n",
    "\n",
    "For mathematical convenience, we will choose $\\mathbf{p_{k}}$'s length to be 1.\n",
    "\n",
    "In compact notation, we have this numerical optimization formulation:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  & maximize(\\mathbf{p_{k}}^{T} \\mathbf{\\Sigma} \\mathbf{p_{k}}) \\\\\n",
    "  & subject\\ to\\ \\mathbf{p_{k}}^{T}\\mathbf{p_{k}} = 1\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "**Note**: We use the definition of [unit vector](https://en.wikipedia.org/wiki/Unit_vector) i.e a vector whose norm is unity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [Method of Lagrange Multipliers](https://en.wikipedia.org/wiki/Lagrange_multiplier), we can write above expression as \n",
    "\n",
    "$$\n",
    " maximize(\\mathbf{f}(\\mathbf{p_{k}})) = maximize(\\mathbf{p_{k}}^{T} \\mathbf{\\Sigma} \\mathbf{p_{k}} + \\lambda_{k}(1-\\mathbf{p_{k}}^{T}\\mathbf{p_{k}}))\n",
    "$$\n",
    "**Note**: $\\lambda_{k}$ is positive scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must find, maximum of above expression, we know from calculus that a [function's maximum value can be found using the first and second derivatives](https://en.wikipedia.org/wiki/Derivative_test#First_derivative_test). What is our variable here? Since we want to find the unknown unit vector $\\mathbf{p_{k}}$ it is our variable. (**Note**: even if magnitude is constant, direction is variable). Hence, we will differentiate it with $\\mathbf{p_{k}}$. \n",
    "\n",
    "Here we would advise user to look at the details of [Matrix Calculus](https://en.wikipedia.org/wiki/Matrix_calculus).\n",
    "\n",
    "**First derivative is given by:**\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{\\partial^1(\\mathbf{f}(\\mathbf{p_{k}}))}{\\partial \\mathbf{p_{k}}^1} &= \\frac{\\partial^1(\\mathbf{p_{k}}^{T} \\mathbf{\\Sigma} \\mathbf{p_{k}} + \\lambda_{k}(1-\\mathbf{p_{k}}^{T}\\mathbf{p_{k}}))}{\\partial \\mathbf{p_{k}}^1} \\\\\n",
    "& = 2\\mathbf{\\Sigma}\\mathbf{p_{k}} - 2\\lambda_{k}\\mathbf{p_{k}}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The condition for critical points (i.e maximum or minimum) is that each component of first vector derivative should be zero i.e \n",
    "\n",
    "$$2\\mathbf{\\Sigma}\\mathbf{p_{k}} - 2\\lambda_{k}\\mathbf{p_{k}} = \\mathbf{0}$$\n",
    "$$\\Rightarrow \\mathbf{\\Sigma}\\mathbf{p_{k}} = \\lambda_{k}\\mathbf{p_{k}} $$\n",
    "\n",
    "The above condition is saying that, if we have to maximize or minimize the projected variance onto $\\mathbf{p_{k}}$, then\n",
    "transformation done by the sample data's co-variance matrix must be equal to the scaling of the $\\mathbf{p_{k}}$ and this is precisely the definition of [eigenvectors and eigenvalues](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors).\n",
    "\n",
    "\n",
    "**Second derivative is given by:**\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{\\partial^2(\\mathbf{f}(\\mathbf{p_{k}}))}{\\partial \\mathbf{p_{k}}^2} &= \\frac{\\partial^1 (\\frac{\\partial^1(\\mathbf{p_{k}}^{T} \\mathbf{\\Sigma} \\mathbf{p_{k}} + \\lambda_{k}(1-\\mathbf{p_{k}}^{T}\\mathbf{p_{k}}))}{\\partial \\mathbf{p_{k}}^1})}{\\partial \\mathbf{p_{k}}^1} \\\\\n",
    "& = \\frac{\\partial^1 (2\\mathbf{\\Sigma}\\mathbf{p_{k}} - \\lambda_{k}\\mathbf{p_{k}})}{\\partial \\mathbf{p_{k}}^1} \\\\\n",
    "& = 2\\mathbf{\\Sigma} - \\lambda_{k}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The condition on a critical point (found by first derivative) to be maximum is that second vector derivative must be positive for each component. i.e\n",
    "\n",
    "$$2\\mathbf{\\Sigma} - \\lambda_{k} \\succ \\mathbf{0} \\ \\ \\ \\text{; Each element is greater than zero} $$\n",
    "$$\\Rightarrow \\mathbf{\\Sigma} \\succ \\frac{\\mathbf{0} +  \\lambda_{k}}{2}$$\n",
    "$$\\Rightarrow \\mathbf{\\Sigma} \\succ \\mathbf{0} \\ \\ \\ \\text{; Since $\\lambda_{k}$ is positive}$$\n",
    "\n",
    "The above condition is saying that co-variance matrix of data i.e $\\mathbf{\\Sigma}$ must be [positive definite](https://en.wikipedia.org/wiki/Positive-definite_matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Additional Principal Components.\n",
    "\n",
    "Note that in the previous sub-section, we didn't assume anything about $\\mathbf{p_{k}}$. Hence, following the above procedure, we could find other principal components i.e $\\mathbf{p_{1}}, \\mathbf{p_{2}}, \\cdots  \\mathbf{p_{i}} \\cdots ,\\mathbf{p_{k}}$ with $ k <= M$. For  mathematical convenience, we choose all the [principal components to be orthogonal to each other](http://mathworld.wolfram.com/OrthogonalVectors.html). i.e \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "dot\\_product(\\mathbf{p_{i}},\\mathbf{p_{j}})  = \\mathbf{p_{i}}\\cdot\\mathbf{p_{j}} = \\mathbf{p_{i}}^{T}\\mathbf{p_{j}} = \n",
    "\\begin{cases}\n",
    "0 & \\text{$ \\forall \\ i \\neq j$}\\\\\n",
    "1 & \\text{$ \\forall \\ i = j$}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Each of the $\\mathbf{p_{i}}$ maximizes the projected variances onto the i'th principal component and can be computed using the eigenvalues and eigenvectors computation of the data samples' co-variance matrix.\n",
    "\n",
    "Also, note that higher the eigenvalues, more is the total projected variances on the corresponding principal component.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Summary of Steps to Compute all the Principal Components.\n",
    "\n",
    "* Collect $N$ samples of $M$ dimensional data.\n",
    "\n",
    "* Standardize it to calculate $N \\times M$ matrix $\\mathbf{S}$ as in section 3.2.4 .\n",
    "\n",
    "* Compute the $M \\times M $ covariance matrix $\\mathbf{\\Sigma}$ as explained in section 3.2.6 .\n",
    "\n",
    "* Compute the [eigenvector and eigenvalues](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors) of $\\mathbf{\\Sigma}$ using [SVD](https://en.wikipedia.org/wiki/Singular-value_decomposition).\n",
    "\n",
    "* Order the eigenvector in decreasing order or eigenvalues.\n",
    "\n",
    "* First vector is the first principal component vector, where the variances is maximum and so on.\n",
    "\n",
    "* Using these techniques, you can compress the data set by using only first $k < M$ principal components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Principal Component Analysis (PCA) in Practice.<a name=\"practice\"></a>\n",
    "\n",
    "We have seen, intuition and mathematical formulation of Principal Component Analysis. Now it's time to play around with real dataset. We will be using [Scikit-learn](http://scikit-learn.org/stable/) and [matplotlib](https://matplotlib.org/) to dive deep into examples.\n",
    "\n",
    "\n",
    "We will look into following four use cases:\n",
    "\n",
    "* [PCA for Dimension Reduction.](#dim_reduction)\n",
    "  \n",
    "* [PCA for Visualization and Better Insights.](#visualization)\n",
    "  \n",
    "* [PCA for Noise Filtering.](#filter_noise)\n",
    "  \n",
    "* [PCA as a Preprocessor for ML algorithms.](#pre_processor)\n",
    "  \n",
    "Let's load relevant library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load high performance linalg lib\n",
    "import numpy as np\n",
    "\n",
    "# pandas util\n",
    "import pandas as pd\n",
    "\n",
    "# load PCA\n",
    "from sklearn.decomposition import  PCA, KernelPCA\n",
    "\n",
    "# load util for datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# load StandardScalar i.e shift by mean and scale by standard deviation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "# load util for datasets\n",
    "from sklearn import datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will use [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) for our initial experiments.\n",
    "\n",
    "Let's first prepare dataset by standardizing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# get X i.e input dataset\n",
    "# get y i.e labelled prediction\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "# Standardization improves the performance of PCA. \n",
    "S = StandardScaler().fit_transform(X)\n",
    "\n",
    "# as discussed before lets standardized the data set\n",
    "\n",
    "print(\"Features or Attributes of iris dataset = \")\n",
    "print(iris[\"feature_names\"])\n",
    "print(\"\\nSamples of input data X = \\n\")\n",
    "print(X[:4,:])\n",
    "\n",
    "print(\"\\nAfter Standardization of Samples of input data X is S = \\n\")\n",
    "print(S[:4,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Standardization improves performance of PCA and if we don't standardized the data, output won't be that great and is illustrated by [this example](http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 PCA for Dimension Reduction (also achieving the data Compression).<a name=\"dim_reduction\"></a>\n",
    "\n",
    "\n",
    "As explained before that dimension reduction has many advantages, and we will illustrate of data compression using PCA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create PCA transformer with 2 principal component\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fit input standardized dataset.\n",
    "prcomp = pca.fit_transform(S)\n",
    "\n",
    "print(\"First few dimensions of 2 principal components\")\n",
    "prcomp[:4,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Principal components that we select are linear combinations of the input data columns\"\n",
    "\n",
    "Let's see, if our principal components contain enough information about the original dataset.\n",
    "\n",
    "Recall that from our discussion in previous sections, we know that PCA maximizes the projected variances. So it's natural to ask that how much variances are contained withing first two principal components. \n",
    "\n",
    "Apart from giving us principal components, PCA transformer also provides us with **explained_variance\\_ratio\\_**, which Scikit-learn provides so that we can know how much variances are captured by each of the principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (\"\\nVariance captured by each principal component = \")\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print (\"\\nTotal Variance captured by principal components = \")\n",
    "total_var = np.cumsum(pca.explained_variance_ratio_)[1]\n",
    "print(total_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, that\n",
    "\n",
    "* Iris dataset has four dimensions i.e 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'. We can only visualize 3 dimensions. So lets reduce the dataset to lower dimensions. We will reduce it to 2 dimensions for our study purpose.\n",
    "\n",
    "* By using 2 dimensions i.e principal component instead of 4 dimensions, we were able to save 50% of memory and thus achieving compression\n",
    "\n",
    "* Since, 2 principal components captures more than 95% of total variance, only 5% information is lost with 50% of memory saving.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 PCA for Visualization and Better Insights.<a name=\"visualization\"></a>\n",
    "\n",
    "Before we do apply ML algorithms, we would like to get better insights into datasets.\n",
    "Note that original data generation process might be lower dimensions but after data collection it becomes higher dimensions. It is easier for human to visualize 3 dimensions or fewer. Since PCA reduces dimensions without much loss of information. Let's walk through an example of visualizing a dataset into lower dimensions.\n",
    "\n",
    "Note that Iris dataset has 4 dimensions, we used PCA to reduce it to 2 dimensions, let's plot the data in the space spanned by first two principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_xlabel('First Principal Component', fontsize = 10)\n",
    "ax.set_ylabel('Second Principal Component', fontsize = 10)\n",
    "ax.set_title('Plotting data using two principal component', fontsize = 15)\n",
    "\n",
    "\n",
    "plt_pr_df = pd.DataFrame(data=prcomp, columns=['pc_1', 'pc_2'])\n",
    "plt_y_df = pd.DataFrame(data=y, columns=['y']) \n",
    "plt_df = pd.concat([plt_pr_df, plt_y_df], axis=1)\n",
    "ax.scatter(plt_df['pc_1'], plt_df['pc_2'],\n",
    "            c=plt_df['y'], edgecolor='none', alpha=0.8,\n",
    "            cmap=plt.cm.get_cmap('RdYlBu_r', 3))\n",
    "\n",
    "#plt.colorbar();\n",
    "ax.legend(targets)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figure, it is clear that using PCA , we can clearly see three different classes. And thus PCA helps in data visualization and in exploratory analysis, we can get better insights into the data without running any classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 PCA for Noise Filtering. <a name=\"filter_noise\"></a>\n",
    "\n",
    "Since PCA select the dimensional axis with maximum total projected variance after optimally rotating the dataset, it follows naturally that if there is the noise in the input dataset and if we apply PCA on it, it will filter out the noise since variance would be much smaller for noise.\n",
    "\n",
    "\n",
    "To bring point home, we will take one image and artificially introduce various noise and see if PCA can remove noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will load one of the images that is shipped with Scikit-learn. Let's first write some of utilities which we will be using multiple times:\n",
    "\n",
    "1. **Normalize Image**: Since image rendered utility in scikit-learn can only display images in the range of 0-1, normalize image utility will divide it with 255 (which is the maximum color levels for RGB format). In above process, introduced noises might make image values to be less than 0 or more than 1, we will also make sure that the range is between 0 and 1.\n",
    "\n",
    "2. **Plot Image**: This utility plots image using matplotlib utilities.\n",
    "\n",
    "3. **Add Guassian Noise**:\n",
    "  Since, in real life, [Guassian noise](https://en.wikipedia.org/wiki/Gaussian_noise) is very common phenomenon, we will add a routine to add Guassian noise. This simulate the situation when we take a picture with noises i.e\n",
    "    * There is over lighting like some flash or sun light, which is modelled by mean of color value.\n",
    "    * And some noises like flickering which is introduced by variance of guassian distribution.\n",
    "  \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_image(img):\n",
    "    \"\"\"\n",
    "    Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "    255 is important so that plt.imshow behaves works well on float data (need to\n",
    "    be in the range [0-1]). Basic idea is this.\n",
    "    norm_image = np.array(image, dtype=np.float64) / 255\n",
    "    \"\"\"\n",
    "    norm_img = np.array(img, dtype=np.float64) / 255\n",
    "    \n",
    "    w, h, d = original_shape = tuple(norm_img.shape)\n",
    "    \n",
    "    norm_img_1d = np.reshape(norm_img, (w * h* d, 1))\n",
    "    norm_img_1d[norm_img_1d > 1.0] = 1\n",
    "    norm_img_1d[norm_img_1d < 0.0] = 0\n",
    "    norm_img = np.reshape(norm_img_1d, (w, h, d))\n",
    "    return norm_img\n",
    "    \n",
    "def plot_color_image(img, title=\"Image\"):\n",
    "    \"\"\"\n",
    "    Utilty to plot image.\n",
    "    \"\"\"\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    ax = plt.axes([0, 0, 1, 1])\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def add_guassian_noise(image):\n",
    "    \"\"\"\n",
    "    Add guassian noise. This simulate the situation when we take a picture \n",
    "    with noises \n",
    "    1) there is over lighting like some flash or sun light, which is introduce by mean 255\n",
    "    2) and some noise like flickering which is introduce by variance 100\n",
    "    \"\"\"\n",
    "    out = image + np.random.normal(255, 100, image.shape)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the \"china.jpg\" image and add some Guassian noise. This simulate the situation when we take a picture with noises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load china image\n",
    "china_org = datasets.load_sample_image('china.jpg')  \n",
    "\n",
    "w, h, d = original_shape = tuple(china_org.shape)\n",
    "    \n",
    "#plot_color_image(normalize_image(china_org))\n",
    "\n",
    "# print(china_org.shape)\n",
    "\n",
    "# add guassian noise to image\n",
    "china_noisy_guass = add_guassian_noise(china_org)\n",
    "\n",
    "china_noisy = china_noisy_guass\n",
    "\n",
    "# plot the noisy image\n",
    "plot_color_image(normalize_image(china_noisy), \"Image with Guassian noise added\")\n",
    "\n",
    "\n",
    "print(\" Image dimensions = \", china_noisy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this image is? Kind of very difficult to answer it. Now lets use PCA to do noise reduction.\n",
    "\n",
    "Typically, a image is represented by 2D array of pixels, where each pixel is of RGB color and there are $width \\times height$ pixels. Thus, total dimensions of this image is $427 \\times 640 \\times 3 = 819840 $ i.e image has about $800k$ dimensions\n",
    "\n",
    "Let's apply linear PCA to this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_norm = normalize_image(china_org)\n",
    "\n",
    "# we will combine color and height dimensions so as to confirm to api of linear PCA and KernelPCA\n",
    "\n",
    "china_noisy_2d = np.reshape(china_noisy, (w ,h * d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.9999)\n",
    "\n",
    "pca = pca.fit(china_noisy_2d)\n",
    "\n",
    "print(\"New dimensions of image = \", pca.n_components_)\n",
    "print(\"Image reconstruction after linear PCA noise filtering\")\n",
    "\n",
    "# transform the noisy image using linear PCA\n",
    "components = pca.transform(china_noisy_2d)\n",
    "filtered = pca.inverse_transform(components)\n",
    "\n",
    "# confirm image into orig 3D\n",
    "china_filtered = np.reshape(filtered, (w , h, d))\n",
    "\n",
    "plot_color_image(normalize_image(china_filtered), \"Image with noise filtered by linear PCA\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that:\n",
    "\n",
    "1. Image's Dimensions reduces significantly from $800,000 $ to around $426$ thus resulting in big saving in data space storage in memory. \n",
    "\n",
    "2. But image is almost same as noisy image in previous sections.\n",
    "\n",
    "\n",
    "To understand second issue, we have to understand that image is actually highly non-linear dataset and hence dimensions reduction using linear PCA probably does not achieve the best result.\n",
    "\n",
    "Is there any better way to reconstructing image? Since image is non-linear data, how about using [KernelPCA](https://en.wikipedia.org/wiki/Kernel_principal_component_analysis)? \n",
    "KernelPCA performs PCA in a new space whose dimensions are nonlinear. Interested user are encouraged to look into details about KernelPCA in previous links.\n",
    "\n",
    "Kernel PCA is very typically used for:\n",
    "\n",
    "* de-noising\n",
    "* novelty detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a kernel PCA transformer\n",
    "# -with inverse_transform so that we can reduce the noise\n",
    "# -gamma controls the strength of cohesiveness of two samples. higher gamma means not so much affected by noise.\n",
    "# -we will remove zero eigenvector\n",
    "# -we will let KernelPCA determine best number of dimensions\n",
    "\n",
    "kpca = KernelPCA(kernel=\"rbf\", fit_inverse_transform=True, gamma=1000, remove_zero_eig = True, n_components = None)\n",
    "\n",
    "kpca = kpca.fit(china_noisy_2d)\n",
    "\n",
    "kcomponents = kpca.transform(china_noisy_2d)\n",
    "\n",
    "# do inverse transform so as to filter our noise.\n",
    "kfiltered = kpca.inverse_transform(kcomponents)\n",
    "\n",
    "# get the 3D image from 2D versoin\n",
    "china_kfiltered = np.reshape(kfiltered, (w , h, d))\n",
    "\n",
    "plot_color_image(normalize_image(china_kfiltered), \"Image with noise filterd by Kernel PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Here, we can see that this is a picture of trees with a tower. Much better than images with noise and image with noise reduction by linear PCA. \n",
    "\n",
    "Now lets look at the original image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_color_image(normalize_image(china_org), \"Original Image with 65k colors\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we saw that using Kernel PCA, we can remove noise from images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 PCA as a Preprocessor for ML algorithms.<a name=\"pre_processor\"></a>\n",
    "\n",
    "\n",
    "We have seen how PCA rotates the dataset so that the dimensional axis align with maximum variance i.e eigenvectors of the Standardized Co-variance Matrix. Doing that allows us, to remove the dimensional axis where the variance is very little and thus achieving\n",
    "\n",
    "1) Data Compression and Dimensional Reduction.\n",
    "2) Reducing and Filtering Noise.\n",
    "3) Making dataset more suitable for applying Machine Learning Algorithms\n",
    "\n",
    "Last point is very important, as we know that most of the machine learning algorithms will perform great, when the data set is more relevant. This property allows us to us PCA as the pre-processing steps to machine learning algorithms (i.e logistic regression, support vector machine etc) and thus achieving better performance.\n",
    "\n",
    "We will not go over the examples in this notebook but interested user can look at following examples to get more details\n",
    "\n",
    "* [Using PCA increase performance of faces detection using SVM classification](http://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py).\n",
    "\n",
    "* [Using PCA to increase performance of K-means clustering](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Summary.<a name=\"summary\"></a>\n",
    "\n",
    "Thus we have given a great details about PCA and various perspective.\n",
    "\n",
    "* First, we looked at the PCA intuition.\n",
    "* Second, we derived PCA from mathematical perspective and connected intuition with rigorous analyis.\n",
    "* Then, we looked at various examples to illustrate various PCA applications like:\n",
    "    * Dimension Reduction.\n",
    "    * Visualization.\n",
    "    * Noise Filtering.\n",
    "    * PCA as pre-processor for better performance of ML algorithms.\n",
    "    \n",
    "    \n",
    "We encourage user to try out various more examples and explore PCA to get deeper insights.    \n",
    "Interested users are encouraged to looked at other alternatives to PCA:\n",
    "\n",
    "* [T-SNE for visualization](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding).\n",
    "* [Isomap non linear dimensional reduction](https://en.wikipedia.org/wiki/Isomap).\n",
    "* [Laplacian Eigenmaps for dimensionality Reduction](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Laplacian_eigenmaps)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
